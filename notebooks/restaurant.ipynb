{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from functools import partial\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pywaffle import Waffle\n",
    "import squarify\n",
    "import scipy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.recommendation import ALSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = spark.read.json(\"../../temp/yelp_json_yelp_academic_dataset_business.json\")\n",
    "review = spark.read.json(\"../../temp/yelp_json_yelp_academic_dataset_review.json\")\n",
    "user = spark.read.json(\"../../temp/yelp_json_yelp_academic_dataset_user.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatings=review.groupBy(\"user_id\").count().select('user_id')\n",
    "window = Window.orderBy(col('user_id'))\n",
    "userRatings = userRatings.withColumn('userid', row_number().over(window))\n",
    "buiRatings=review.groupBy(\"business_id\").count().select('business_id')\n",
    "window = Window.orderBy(col('business_id'))\n",
    "buiRatings = buiRatings.withColumn('businessid', row_number().over(window))\n",
    "newratings=review.join(userRatings, ['user_id'])\n",
    "newratings=newratings.join(buiRatings, ['business_id'])\n",
    "newratings=newratings.withColumn(\"stars\",col(\"stars\").cast(IntegerType()))\n",
    "newratings=newratings.withColumn(\"date\",to_timestamp(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review.show(5)\n",
    "business.show(5)\n",
    "user.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Average <a class=\"anchor\" id=\"Weighted_average\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg,count\n",
    "res=newratings.groupBy('businessid','business_id').agg(avg(\"stars\").alias(\"meanStar\"),count('stars').alias('numRate'))\n",
    "\n",
    "C = res.select(mean ('meanStar')).collect()[0][0]\n",
    "m = res.approxQuantile(\"numRate\", [0.7], 0.25)[0]\n",
    "\n",
    "C, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_res = res.where(col('numRate')>=m)\n",
    "q_res.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating(x, m=m, C=C):\n",
    "    v=x.toPandas()['numRate']\n",
    "    R=x.toPandas()['meanStar']\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = weighted_rating(q_res)\n",
    "\n",
    "q_ress=q_res.toPandas()\n",
    "q_ress['score']=score\n",
    "q_ress = spark.createDataFrame(q_ress) \n",
    "# q_ress=q_res.withColumn('score',lit(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ress.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ressPD=q_ress.join(business,['business_id'])\n",
    "q_ressPD = q_ressPD.toPandas().sort_values('score', ascending=False)\n",
    "q_ressPD[['businessid','business_id', 'name','score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/res_scores.pickle', 'wb') as handle:\n",
    "    pickle.dump(q_ressPD[['business_id', 'name','score']], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content based <a class=\"anchor\" id=\"Content_based\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536315"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new=newratings.groupBy('businessid').agg(avg(\"stars\").alias(\"meanStar\"),count('stars').alias('numRate'))\n",
    "new=new.filter(col('meanStar')>4.6)\n",
    "temp=new.join(newratings,['businessid'])\n",
    "butemp=business.select('business_id','name')\n",
    "temp=temp.join(butemp,['business_id'])\n",
    "del butemp\n",
    "temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=spark.read.json('../data/res_df.json/')\n",
    "g.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res=temp.join(business,['business_id']).select('name','review_id')\n",
    "new_res.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res.write.format(\"json\").mode(\"overwrite\").save(\"../data/ress_df.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniqueDF(df):\n",
    "    window_spec = Window.partitionBy('businessid').orderBy(col('stars').desc(),col('date').desc(),length('text').desc())\n",
    "    df_with_row_number = df.withColumn('row_number', row_number().over(window_spec))\n",
    "    df_with_row_number=df_with_row_number.filter(col('row_number')==1).select('review_id','business_id','businessid','text','meanStar','name')\n",
    "    return df_with_row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_row_number=getUniqueDF(temp)\n",
    "df_with_row_number.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_row_number.write.format(\"json\").mode(\"overwrite\").save(\"../data/temp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>businessid</th>\n",
       "      <th>text</th>\n",
       "      <th>meanStar</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g7wkIEW9sBV7xYg2AzkGrw</td>\n",
       "      <td>-5ink0kIoVfuS5Zi_6QBnQ</td>\n",
       "      <td>243</td>\n",
       "      <td>Liberties Parcel is my go-to place to ship and...</td>\n",
       "      <td>4.958904</td>\n",
       "      <td>Liberties Parcel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wkRIxZ4H8O_R3qgmmPN22A</td>\n",
       "      <td>-LiECrK7Cunuy0RAaKVmhQ</td>\n",
       "      <td>833</td>\n",
       "      <td>VIP Collision was amazing! Needed a bumper pai...</td>\n",
       "      <td>4.712329</td>\n",
       "      <td>VIP Collision Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NfuW7wxMGIQU657ydGD6jA</td>\n",
       "      <td>-duPMGeNQSCGEUl0s552Cw</td>\n",
       "      <td>1522</td>\n",
       "      <td>Having lived in philly was excited when this o...</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>Rita's Italian Ice &amp; Frozen Custard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKIaEBJ39QK4_u9WexmIbQ</td>\n",
       "      <td>-fgqxSoaPN3QrB7FrIxk7Q</td>\n",
       "      <td>1591</td>\n",
       "      <td>I came to Caliber after being rear ended. The ...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>Caliber Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22m2a3hDaD3n1eD8sqWMLQ</td>\n",
       "      <td>-nJid5B14dYu1wPtMp149g</td>\n",
       "      <td>1884</td>\n",
       "      <td>Great product made fresh to order.\\nI had the ...</td>\n",
       "      <td>4.812500</td>\n",
       "      <td>MJ's Backyard BBQ and Catering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id             business_id  businessid  \\\n",
       "0  g7wkIEW9sBV7xYg2AzkGrw  -5ink0kIoVfuS5Zi_6QBnQ         243   \n",
       "1  wkRIxZ4H8O_R3qgmmPN22A  -LiECrK7Cunuy0RAaKVmhQ         833   \n",
       "2  NfuW7wxMGIQU657ydGD6jA  -duPMGeNQSCGEUl0s552Cw        1522   \n",
       "3  WKIaEBJ39QK4_u9WexmIbQ  -fgqxSoaPN3QrB7FrIxk7Q        1591   \n",
       "4  22m2a3hDaD3n1eD8sqWMLQ  -nJid5B14dYu1wPtMp149g        1884   \n",
       "\n",
       "                                                text  meanStar  \\\n",
       "0  Liberties Parcel is my go-to place to ship and...  4.958904   \n",
       "1  VIP Collision was amazing! Needed a bumper pai...  4.712329   \n",
       "2  Having lived in philly was excited when this o...  4.727273   \n",
       "3  I came to Caliber after being rear ended. The ...  5.000000   \n",
       "4  Great product made fresh to order.\\nI had the ...  4.812500   \n",
       "\n",
       "                                  name  \n",
       "0                     Liberties Parcel  \n",
       "1                 VIP Collision Center  \n",
       "2  Rita's Italian Ice & Frozen Custard  \n",
       "3                    Caliber Collision  \n",
       "4       MJ's Backyard BBQ and Catering  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=df_with_row_number.toPandas()\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/res_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(temp[['review_id','business_id','name']], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g7wkIEW9sBV7xYg2AzkGrw</td>\n",
       "      <td>-5ink0kIoVfuS5Zi_6QBnQ</td>\n",
       "      <td>Liberties Parcel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wkRIxZ4H8O_R3qgmmPN22A</td>\n",
       "      <td>-LiECrK7Cunuy0RAaKVmhQ</td>\n",
       "      <td>VIP Collision Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NfuW7wxMGIQU657ydGD6jA</td>\n",
       "      <td>-duPMGeNQSCGEUl0s552Cw</td>\n",
       "      <td>Rita's Italian Ice &amp; Frozen Custard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WKIaEBJ39QK4_u9WexmIbQ</td>\n",
       "      <td>-fgqxSoaPN3QrB7FrIxk7Q</td>\n",
       "      <td>Caliber Collision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22m2a3hDaD3n1eD8sqWMLQ</td>\n",
       "      <td>-nJid5B14dYu1wPtMp149g</td>\n",
       "      <td>MJ's Backyard BBQ and Catering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id             business_id  \\\n",
       "0  g7wkIEW9sBV7xYg2AzkGrw  -5ink0kIoVfuS5Zi_6QBnQ   \n",
       "1  wkRIxZ4H8O_R3qgmmPN22A  -LiECrK7Cunuy0RAaKVmhQ   \n",
       "2  NfuW7wxMGIQU657ydGD6jA  -duPMGeNQSCGEUl0s552Cw   \n",
       "3  WKIaEBJ39QK4_u9WexmIbQ  -fgqxSoaPN3QrB7FrIxk7Q   \n",
       "4  22m2a3hDaD3n1eD8sqWMLQ  -nJid5B14dYu1wPtMp149g   \n",
       "\n",
       "                                  name  \n",
       "0                     Liberties Parcel  \n",
       "1                 VIP Collision Center  \n",
       "2  Rita's Italian Ice & Frozen Custard  \n",
       "3                    Caliber Collision  \n",
       "4       MJ's Backyard BBQ and Catering  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/res_df.pickle', 'rb') as handle:\n",
    "    movie = pickle.load(handle)\n",
    "movie.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(numFeatures=10000,inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf])\n",
    "model = pipeline.fit(df_with_row_number)\n",
    "result = model.transform(df_with_row_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.format(\"json\").mode(\"overwrite\").save(\"../data/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=spark.read.json('../data/results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=result.select('business_id','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.write.parquet(\"../data/tfidfs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=spark.read.parquet('../data/tfidfs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_udf = udf(lambda x, y: float(x.dot(y)) / (x.numNonzeros() * y.numNonzeros()), DoubleType())\n",
    "joined_data = matrix.alias('d1').join(matrix.alias('d2'), on=col('d1.business_id') != col('d2.business_id'))\n",
    "similarity_scores = joined_data.select(col('d1.business_id').alias('business_id_1'), col('d2.business_id').alias('business_id_2'), similarity_udf(col('d1.features'), col('d2.features')).alias('similarity'))\n",
    "top_related_businesses = similarity_scores.groupBy('business_id_1').agg(collect_list(struct('business_id_2', 'similarity')).alias('related_businesses'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_related_businesses = top_related_businesses.withColumn('top10_related_businesses', udf(lambda related_businesses: [x[0] for x in sorted(related_businesses, key=lambda x: x[1], reverse=True)[:5]], ArrayType(StringType()))(col('related_businesses'))).select('business_id_1', 'top10_related_businesses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_related_businesses.write.format('json').mode(\"overwrite\").save(\"../data/related.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import SparseVector\n",
    "\n",
    "num_features=10000\n",
    "sparse_vectors = matrix.rdd.map(lambda row: row['features'].toArray()) \\\n",
    "                             .map(lambda arr: SparseVector(num_features, [(i, arr[i]) for i in range(num_features)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = sparse_vectors.cartesian(sparse_vectors).map(lambda x: (x[0][0], x[1][0], x[0][1].dot(x[1][1])))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id1\", IntegerType(), True),\n",
    "    StructField(\"id2\", IntegerType(), True),\n",
    "    StructField(\"similarity\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "similarity_df = similarity_matrix.toDF(schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = similarity_df.select(\"*\", monotonically_increasing_id().alias(\"row_id\"))\n",
    "\n",
    "# Optionally, cache the DataFrame for better performance\n",
    "similarity_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = sparse_vectors.cartesian(sparse_vectors).map(lambda x: (x[0].dot(x[1]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_rows = similarity_matrix.filter(lambda row: len(row) >= 3) \\\n",
    "    .map(lambda row: Row(id1=row[0], id2=row[1], similarity=row[2])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# similarity_rows = similarity_matrix.filter(lambda x: len(x) >= 3).map(lambda x: Row(id1=x[0], id2=x[1], similarity=x[2])).collect()\n",
    "\n",
    "similarity_rows = similarity_matrix.filter(lambda row: len(row) >= 3) \\\n",
    "    .map(lambda row: Row(id1=row[0], id2=row[1], similarity=row[2])).toDF()\n",
    "\n",
    "# similarity_df = spark.createDataFrame(similarity_rows)\n",
    "\n",
    "# similarity_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df.write.parquet(\"../data/similarity.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = sparse_vectors.cartesian(sparse_vectors).map(lambda x: (x[0].dot(x[1]),)).toDF(['similarity'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21905, 34792)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "a['text'] = a['text'].fillna('')\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(a['text'])\n",
    "tfidf_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = scipy.sparse.load_npz('../data/res_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "indices = pd.Series(a.index, index=a['name']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(text, cosine_sim=cosine_sim):\n",
    "    idx = indices[text]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    res_indices = [i[0] for i in sim_scores]\n",
    "    res_similarity = [i[1] for i in sim_scores]\n",
    "\n",
    "    return pd.DataFrame(zip(a['name'].iloc[res_indices], res_similarity), columns=[\"name\", \"similarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('../data/res_matrix.npz', tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('Liberties Parcel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
